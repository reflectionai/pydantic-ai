interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '740'
      content-type:
      - application/json
      host:
      - api.anthropic.com
    method: POST
    parsed_body:
      max_tokens: 4096
      messages:
      - content:
        - text: What is the largest city in the user country? Use the get_user_country tool and then your own world knowledge.
          type: text
        role: user
      model: claude-3-5-sonnet-latest
      stream: false
      system: |+
        Always respond with a JSON object that's compatible with this schema:

        {"properties": {"city": {"type": "string"}, "country": {"type": "string"}}, "required": ["city", "country"], "title": "CityLocation", "type": "object"}

        Don't include any text or Markdown fencing before or after.

      tool_choice:
        type: auto
      tools:
      - description: ''
        input_schema:
          additionalProperties: false
          properties: {}
          type: object
        name: get_user_country
    uri: https://api.anthropic.com/v1/messages?beta=true
  response:
    headers:
      connection:
      - keep-alive
      content-length:
      - '476'
      content-type:
      - application/json
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      content:
      - id: toolu_01ArHq5f2wxRpRF2PVQcKExM
        input: {}
        name: get_user_country
        type: tool_use
      id: msg_018YiNXULHGpoKoHkTt6GivG
      model: claude-3-5-sonnet-20241022
      role: assistant
      stop_reason: tool_use
      stop_sequence: null
      type: message
      usage:
        cache_creation:
          ephemeral_1h_input_tokens: 0
          ephemeral_5m_input_tokens: 0
        cache_creation_input_tokens: 0
        cache_read_input_tokens: 0
        input_tokens: 459
        output_tokens: 38
        service_tier: standard
    status:
      code: 200
      message: OK
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '1002'
      content-type:
      - application/json
      host:
      - api.anthropic.com
    method: POST
    parsed_body:
      max_tokens: 4096
      messages:
      - content:
        - text: What is the largest city in the user country? Use the get_user_country tool and then your own world knowledge.
          type: text
        role: user
      - content:
        - id: toolu_01ArHq5f2wxRpRF2PVQcKExM
          input: {}
          name: get_user_country
          type: tool_use
        role: assistant
      - content:
        - content: Mexico
          is_error: false
          tool_use_id: toolu_01ArHq5f2wxRpRF2PVQcKExM
          type: tool_result
        role: user
      model: claude-3-5-sonnet-latest
      stream: false
      system: |+
        Always respond with a JSON object that's compatible with this schema:

        {"properties": {"city": {"type": "string"}, "country": {"type": "string"}}, "required": ["city", "country"], "title": "CityLocation", "type": "object"}

        Don't include any text or Markdown fencing before or after.

      tool_choice:
        type: auto
      tools:
      - description: ''
        input_schema:
          additionalProperties: false
          properties: {}
          type: object
        name: get_user_country
    uri: https://api.anthropic.com/v1/messages?beta=true
  response:
    headers:
      connection:
      - keep-alive
      content-length:
      - '459'
      content-type:
      - application/json
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      content:
      - text: '{"city": "Mexico City", "country": "Mexico"}'
        type: text
      id: msg_01WiRVmLhCrJbJZRqmAWKv3X
      model: claude-3-5-sonnet-20241022
      role: assistant
      stop_reason: end_turn
      stop_sequence: null
      type: message
      usage:
        cache_creation:
          ephemeral_1h_input_tokens: 0
          ephemeral_5m_input_tokens: 0
        cache_creation_input_tokens: 0
        cache_read_input_tokens: 0
        input_tokens: 510
        output_tokens: 17
        service_tier: standard
    status:
      code: 200
      message: OK
version: 1
...
